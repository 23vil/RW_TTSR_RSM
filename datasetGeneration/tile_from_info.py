"""
tile_from_info.py
-------
TTSR generate image tile pairs - STEP 2:
Generates your training data - consisting of pairs of HR-LR tiles.
This script is for generating consistent, GPU-friendly training data, with the
guidance from the .csv file generated by 'gen_sample_info.py'.

Parameters:
-------
- out: Path, relative path where the dataset to be generated will be saved.
- info: Path, relative path to the 'guidemap' .csv file generated by
        'gen_sample_info.py'.
- tile: int, generated tile size.
- n_train: int, number of training tiles.
- n_valid: int, number of validation tiles.
- only: str, generate training data only from the specified categories. All
        categories are included by default. (optional)
- skip: str, generate training data from all categories EXCEPT the specified
        categories, e.g. ['cat1', 'cat2']. None is skipped by default. (optional)
- clean: boolean, TRUE if wiping existing data in the output folder first,
         FALSE by default. (optional)

Returns:
-------
- a .csv file that stores the metadata information about the cropped tiles.
- training image pairs/tiles will be saved on disk.

Examples:
-------

Example 1: The info file all.csv shall be used. Then, generate 500 training pairs and 50 validation pairs with tile size
32x32. All subcategories are used except the 'MgAlCa_1024x1024_to_4096x4096' and '...' folder. 

---> python tile_from_info.py --out datasets --info all.csv --n_train 500 --n_valid 50  --tile 32 --skip ['MgAlCa_1024x1024_to_4096x4096', '...']



Example 2: The info file all.csv shall be used. Then, generate 400 training pairs and 40 validation pairs with tile size
113x113. Only tiles generated from the subcategory MgAlCa_1024x1024_to_4096x4096 will be added to the dataset. Because 
--clean is added at the end, the output folder 'all' in /home/datasetfolder will be wiped before new images are added. 
Be carefull with this option! Data cannot be brought back!

---> python tile_from_info.py --out /home/datasetfolder --info all.csv --n_train 400 --n_valid 40  --tile 113 --only MgAlCa_1024x1024_to_4096x4096 --clean

"""

import yaml
from fastai.script import *
from fastai.vision import *
#import pandas as pd
#import numpy as np
from fastprogress import master_bar, progress_bar
from utils import *
from pathlib import Path
from time import sleep
import shutil
import PIL
PIL.Image.MAX_IMAGE_PIXELS = 99999999999999

def need_cache_flush(tile_stats, last_stats):
    if last_stats is None: return True
    if tile_stats['HRfn'] != last_stats['HRfn'] and tile_stats['LRfn'] != last_stats['LRfn']: return True
    return False

def get_tile_puller(tile_stat):#, crap_func, t_frames, z_frames):
    HRfn = tile_stat['HRfn']
    LRfn = tile_stat['LRfn']
    ftype = tile_stat['ftype']

    if True:
        HR_pil_img = PIL.Image.open(HRfn)
        LR_pil_img = PIL.Image.open(LRfn)
        def pil_get(istat):
            c,x,y,mi,ma,is_uint8,rmax,all_rmax,all_ma = [istat[fld] for fld in ['c','LRx','LRy','LRmi','LRma','uint8','LRrmax','LRall_rmax','LRall_ma']]

            if is_uint8:
                mi, ma, rmax = 0., 255.0, 255.0
                all_ma, all_rmax = 255.0, 255.0

            HR_img_array = []    
            HRimg = np.array(HR_pil_img)
            if len(HRimg.shape) > 2: HRimg = HRimg[:,:,0]
            HR_img_array.append(HRimg.copy())   
             
             
            LR_img_array = []
            LRimg = np.array(LR_pil_img)
            if len(LRimg.shape) > 2: LRimg = LRimg[:,:,0]
            LR_img_array.append(LRimg.copy())    
                
                

            HRimg = np.stack(HR_img_array)
            HRimg = HRimg.astype(np.float32)
            HRimg /= all_rmax
            
            LRimg = np.stack(LR_img_array)
            LRimg = LRimg.astype(np.float32)
            LRimg /= all_rmax
            
            img = [HRimg, LRimg]
            return img  
        
        img_get = pil_get #img_get is full frame image
        img_get._to_close = HR_pil_img

    #puller is executed right after the above
    def puller(istat, hr_folder, lr_folder, close_me=False):
        if close_me:
            img_get._to_close.close()
            return None
        
        
        id = istat['index']
        HRfn = Path(istat['HRfn'])
        LRfn = Path(istat['LRfn'])
        tile_sz = istat['tile_sz']
        c,x,y,mi,ma,is_uint8,rmax = [istat[fld] for fld in ['c','LRx','LRy','LRmi','LRma','uint8','LRrmax']]

        raw_data = img_get(istat)
        HR_raw_data = raw_data[0]
        LR_raw_data = raw_data[1]
        
        HR_img_data = (np.iinfo(np.uint8).max * HR_raw_data).astype(np.uint8)
        LR_img_data = (np.iinfo(np.uint8).max * LR_raw_data).astype(np.uint8)
        
        LRthresh = np.percentile(LR_img_data, 2)
        LRthresh_pct = (LR_img_data > LRthresh).mean() * 0.30

        HRframe_count = HR_img_data.shape[0]
        LRframe_count = LR_img_data.shape[0]
        
        HRmid_frame = HRframe_count // 2
        LRmid_frame = LRframe_count // 2
        
        if (HR_img_data.shape[0] % LR_img_data.shape[0] == 0):
            magnification = int(HR_img_data.shape[1] / LR_img_data.shape[1])

        else:
            print("Mismatch in HR-LR Image Sizes")


        boxEstDeviationXY = None
        

        
        while boxEstDeviationXY == None or boxEstDeviationXY[0] not in range(-12,13) or boxEstDeviationXY[1] not in range(-12,13):      
            try:
                LR_crop_img, LRbox = draw_random_tile(LR_img_data[LRmid_frame], istat['tile_sz'], LRthresh, LRthresh_pct) ## Original HR Image Crop is done here
                ##box contains information about the tiles position in the full frame image....box = [xs.start, ys.start, xs.stop, ys.stop] 
                specTile = draw_specific_tile(HR_img_data[HRmid_frame], LR_crop_img, LRbox, magnification)
                HRboxEstimate =LRbox*magnification
                boxEstDeviationXY=specTile[3]
                SSIM = specTile[1]
                PSNR = specTile[2]
            except:
                boxEstDeviationXY = None

            
        LR_crop_img.save(lr_folder/f'{id:06d}_{LRfn.stem}.tif')
        HR_crop_img = specTile[0]
        HR_crop_img.save(hr_folder/f'{id:06d}_{HRfn.stem}.tif')
        
        

        info = dict(istat)
        info['id'] = id
        info['box'] = LRbox
        info['HRboxEstimate'] = HRboxEstimate
        info['HRboxDeviation'] = boxEstDeviationXY
        info['tile_sz'] = tile_sz
        crop_data = np.array(HR_crop_img)
        info['after_mean'] = crop_data.mean()
        info['after_sd'] = crop_data.std()
        info['after_max'] = crop_data.max()
        info['after_min'] = crop_data.min()
        info['SSIM'] = specTile[1]
        info['PSNR'] = specTile[2]
        info['LRfilename'] = f'{id:06d}_{LRfn.stem}.tif'
        info['HRfilename'] = f'{id:06d}_{HRfn.stem}.tif'
        return info

    return puller #puller itself return info



@call_parse
def main(out: Param("dataset folder", Path, required=True),
         info: Param('info file', Path, required=True),
         tile: Param('generated tile size', int, nargs='+', required=True),
         n_train: Param('number of train tiles', int, required=True),
         n_valid: Param('number of validation tiles', int, required=True),
         only: Param('limit to these categories', nargs='+') = None,
         skip: Param("categories to skip", str, nargs='+') = ['random', 'ArgoSIMDL'],
         clean: Param("wipe existing data first", action='store_true') = False):

    #Dataset output folder
    out = ensure_folder(out/f'{info.stem}_RW')
    
    #Deletes every file and folder in out
    if clean:
        shutil.rmtree(out)
    
    #Read .csv file specified in --info
    info = pd.read_csv(info)  # Info File is read
    
    
    # Enforce --skip and --only settings
    if only: info = info.loc[info.category.isin(only)]
    elif skip: info = info.loc[~info.category.isin(skip)]


    tile_infos = []
    
    
    #First generate n_train * training data, then n_valid * validation data. valid and train are further refered to as modes.
    for mode, n_samples in [('train', n_train),('valid', n_valid)]:
        #filter the info dataframe to only contain lines with respect to the current mode (train or valid)
        mode_info = info.loc[info.dsplit == mode] #dsplit is the column with train&valid --> mode_info is lines for training or valid
        #filter for a defined category (as defined with --skip or --only) 
        categories = list(mode_info.groupby('category'))         
        files_by_category  = {c:list(info.groupby('HRfn')) for c,info in categories} 
        
        #Run the following code n_samples times:
        for i in range(n_samples): 
            category, cat_df = random.choice(categories) #Determine catergory of n-th sample randomly
            HRfn, HRitem_df = random.choice(files_by_category[category]) #Randomly select a HR image from the catergory selected above
            LRfn = HRitem_df.iloc[0].LRfn #Find LR file that corresponds to the HR file above.
            
            #further restrictions can be added here:
            legal_choices = [item_info for ix, item_info in HRitem_df.iterrows() if True]
            assert(legal_choices) #checks if legal_choices is True
            item_info = random.choice(legal_choices)
            
            #Tile Sizes defined by paramater --tile are enforced here
            for tile_sz in tile:
                item_d = dict(item_info)
                item_d['tile_sz'] = tile_sz 
                tile_infos.append(item_d) #adds tile_sz to info

    tile_info_df = pd.DataFrame(tile_infos).reset_index()
    print('num tile pulls:', len(tile_infos))
    #print(tile_info_df.groupby('category').HRfn.count())

    last_stat = None
    tile_pull_info = []
    tile_puller = None
    mbar = master_bar(tile_info_df.groupby('HRfn'))
    #generate all tile pairs:
    for HRfn, tile_stats in mbar:
        for i, tile_stat in progress_bar(list(tile_stats.iterrows()), parent=mbar):
            try:
                mode = tile_stat['dsplit']
                category = tile_stat['category']
                tile_sz = tile_stat['tile_sz']
                hr_folder = ensure_folder(out / f'{category}_{tile_sz}' / mode / f'HR')
                lr_folder = ensure_folder(out / f'{category}_{tile_sz}' / mode / f'LR')

                if need_cache_flush(tile_stat, last_stat):
                    if tile_puller:
                        tile_puller(None, None, None, close_me=True)
                    last_stat = tile_stat.copy()
                    tile_sz = tile_stat['tile_sz']
                    tile_puller = get_tile_puller(tile_stat)#,t_frames, z_frames) #tile_stat contains full pd.dataframe
                tile_pull_info.append(tile_puller(tile_stat, hr_folder, lr_folder))
                
            except MemoryError as error:
                # some files are too big to read
                fn = Path(tile_stat['HRfn'])
                print(f'too big: {fn.stem}')
    for item in os.listdir(out):       
        if os.path.isdir(os.path.join(out,item)):
            pd.DataFrame(tile_pull_info).to_csv(out / item / f'tiles.csv', index = False)
